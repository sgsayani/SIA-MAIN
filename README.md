<h1> Smart Insight Automation real-time data  </h1>
Our goal is to develop a program that utilizes a webcam or external camera as an input device. The program will recognize and classify gestures into established categories.

The program will have several features that will activate through various facial, ocular, and manual gestures. To accomplish these tasks, we will employ machine learning methods using the Python programming language.

**Components:**  Python | VSCode(IDE)<br>
**Libraries:** OpenCV | NumPy | TensorFlow | Media pipe | Tkinter

**Project Video Link:**  https://drive.google.com/file/d/1q1GnFtpq1aYaaATI38nSV79oPcGgXAWv/view?usp=drive_link

Although gesture recognition has the potential to reduce our reliance on handheld devices, there is an alternative path that could lead to a wide range of specialized input devices. In the future, custom devices could be designed for nearly every type of activity in a virtual environment. Currently, the desktop interface primarily focuses on the keyboard and mouse. Despite recent advancements in handwriting recognition, voice recognition, gesture recognition, haptics, eye-tracking, and wearable computers, usability issues have prevented these from becoming mainstream. Our objective is to create a user-friendly and efficient application that performs all necessary functions, to ensure mainstream recognition.

**Marketing**
There is a notable transformation occurring within the automotive sector, propelled by the enhanced capabilities of software applications and a considerable reduction in expenses. For a considerable period, utilizing accelerometers to gauge motion has been a common practice, particularly when used as input signals for computers. Nevertheless, at present, there are no advanced applications available that can offer a comprehensive solution to multiple functions utilizing gestures. The introduction of such an application would be immensely beneficial in resolving numerous issues.





